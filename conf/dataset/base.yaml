dataset:
  name: examples
  size: L
  root_path: ${env:GERL}/data/${dataset.size}/${dataset.name}
  result_path: ${env:GERL}/data/${dataset.size}/result/
  train: ${dataset.root_path}/training_examples
  valid: ${dataset.root_path}/eval_examples.tsv
  valid_sample: ${dataset.root_path}/eval_examples.sample.tsv
  test: ${dataset.root_path}/test_examples
  vocab_subdir: data/vocabs
  user_vocab: ${env:GERL}/${dataset.vocab_subdir}/userid_vocab.bin
  word_vocab: ${env:GERL}/${dataset.vocab_subdir}/word_vocab.bin
  word_embedding: ${env:GERL}/${dataset.vocab_subdir}/word_embeddings.bin.npy
  title_embedding: ${env:GERL}/data/${dataset.size}/news_title.npy
  max_news_len: 20
  max_user_one_hop: 50
  max_user_two_hop: 15
  max_news_two_hop: 15
  user_count: 900000
  news_count: 140000
  train_split_cnt: 40
  valid_split_cnt: 4
  test_split_name: p0
